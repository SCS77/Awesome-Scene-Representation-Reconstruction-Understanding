<h1 align="center">
  <b>Awesome-Scene-Representation-Reconstruction-Understanding</b>
</h1>

ğŸ“¦ A curated collection of papers, datasets, codebases, and resources on Scene Representation, Reconstruction, and Understanding. This list covers both classical and modern approaches, including NeRF, 3D Gaussian Splatting (3DGS), multi-view geometry, SLAM, semantic parsing, neural scene rendering, and embodied perception.

## ğŸ˜„ğŸ˜„ <span style="color:red;">Under Construction</span>  ğŸ˜„ğŸ˜„

## [ğŸ‘ Scene Representation](#scene-representation)  
## [ğŸ”¥ Scene Reconstruction](#scene-reconstruction)  
## [ğŸš€ Scene Understanding](#scene-understanding)  

---

## Scene Representation
> #### <span style="color:lightblue;">ğŸ’¡ Scene Representation: This refers to the data structures or mathematical models used to store, manipulate, and render reconstructed scene information. It serves as the â€œlanguageâ€ computers employ to describe the three-dimensional world. The choice of representationâ€”whether discrete point clouds, meshes, or continuous neural fieldsâ€”directly determines the efficiency and possibilities of subsequent processing.</span>  

> #### <span style="color:Lightpink;">ğŸ’¡ğŸ’¡ Representation methods for three-dimensional scenes can be broadly categorized into two main types: explicit representation and implicit representation. Explicit representations directly define geometric shapes, such as point clouds, voxels, and polygonal meshes, which describe an object's surface or volume through a set of discrete elements (points, cubes, or polygons). In contrast, implicit representations define geometry through a function, where the object's surface is typically a level set of that function (e.g., the zero level set). Symbolic distance functions (SDFs) represent a classic implicit representation, while the recently emerging neural radiance fields (NeRFs) learn a continuous function via neural networks to represent the volumetric properties of an entire scene. The latest 3D Gaussian Splatter (3DGS) can be viewed as a modern hybrid approach, employing explicit primitives (Gaussian functions) whose parameters are learned through an optimization process similar to neural fields.</span>  


>#### Table:Comparison of Representation Methods Across Different Scenarios
| è¡¨ç¤ºæ–¹æ³•   | æ ¸å¿ƒå›¾å…ƒ            | æ•°æ®ç»“æ„              | æ€§è´¨ | å…³é”®ä¼˜åŠ¿                                         | å…³é”®åŠ£åŠ¿                                                     |
|------------|----------------------|------------------------|------|--------------------------------------------------|--------------------------------------------------------------|
| ç‚¹äº‘       | ä¸‰ç»´ç‚¹ (x, y, z, ...) | æ— åºç‚¹é›†              | æ˜¾å¼ | çµæ´»ï¼Œç›´æ¥ä»ä¼ æ„Ÿå™¨è·å–                           | æ— åºï¼Œéç»“æ„åŒ–ï¼Œç¼ºä¹æ‹“æ‰‘ä¿¡æ¯                                 |
| ä½“ç´ ç½‘æ ¼   | ç«‹æ–¹ä½“ï¼ˆä½“ç´ ï¼‰       | ä¸‰ç»´è§„åˆ™/ç¨€ç–ç½‘æ ¼      | æ˜¾å¼ | è§„æ•´ç»“æ„ï¼Œé€‚ç”¨äº 3D CNN                          | å†…å­˜æ¶ˆè€—å¤§ï¼Œåˆ†è¾¨ç‡å—é™                                       |
| å¤šè¾¹å½¢ç½‘æ ¼ | é¡¶ç‚¹ã€è¾¹ã€é¢         | å›¾/åŠè¾¹ç»“æ„           | æ˜¾å¼ | æ‹“æ‰‘æ˜ç¡®ï¼Œæ¸²æŸ“é«˜æ•ˆï¼Œæ˜“äºç¼–è¾‘                     | æ‹“æ‰‘å›ºå®šï¼Œéš¾ä»¥è¡¨ç¤ºå¤æ‚æˆ–éæµå½¢å‡ ä½•                           |
| NeRF       | -                    | ç¥ç»ç½‘ç»œï¼ˆMLPï¼‰        | éšå¼ | é«˜çœŸå®æ„Ÿï¼Œèƒ½è¡¨ç¤ºå¤æ‚å…‰å­¦æ•ˆåº”                     | è®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦æ…¢ï¼Œéš¾ä»¥ç¼–è¾‘                                   |
| 3DGS       | ä¸‰ç»´é«˜æ–¯å‡½æ•°         | é«˜æ–¯å‚æ•°åˆ—è¡¨           | æ··åˆ | å®æ—¶æ¸²æŸ“ï¼Œç…§ç‰‡çº§çœŸå®æ„Ÿ                           | å­˜å‚¨å¼€é”€å¤§ï¼Œç¼–è¾‘å›°éš¾ï¼Œä¾èµ– SfM                               |


### Point cloud
> #### <span style="color:lightblue;">ğŸ’¡ Point Clouds: This is the most direct output format for many sensors (such as LiDAR) and reconstruction algorithms (such as SfM and MVS). It represents a simple collection of three-dimensional coordinate points (X, Y, Z), often accompanied by attributes like color (RGB) and normals. Point clouds offer the advantages of simple structure and ease of acquisition. However, their drawback lies in the absence of explicit topological connection information, making it challenging to perform high-quality rendering or surface analysis directly.</span>

[[code]](https://github.com/charlesq34/pointnet.git) [[paper]](https://openaccess.thecvf.com/content_cvpr_2017/papers/Qi_PointNet_Deep_Learning_CVPR_2017_paper.pdf)  PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation [CVPR 2017]  
[[code]](https://github.com/charlesq34/pointnet2.git) [[paper]](https://dl.acm.org/doi/abs/10.5555/3295222.3295263) PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space [NIPS 2017]




### Voxel
> #### <span style="color:lightblue;">ğŸ’¡ Voxel Grids: As an extension of pixels in three-dimensional space, voxel grids divide space into regular cubic units (voxels). Each voxel can store occupancy information (i.e., whether the space is occupied), color, or other attributes. This structured representation facilitates Boolean operations and volumetric analysis, but its memory consumption increases cubically with resolution and can produce jagged edges due to discretization.</span>








### Polygon Mesh
> #### <span style="color:lightblue;">ğŸ’¡ Polygon Meshes: This has long been the dominant representation method in computer graphics. It consists of vertices, edges, and faces (typically triangles or quadrilaterals), explicitly defining an object's surface topology. Mesh representations are highly efficient for hardware-accelerated rendering and provide explicit surface information. However, generating high-quality, flawless meshesâ€”such as those that are watertight and free of self-intersectionsâ€”is often a complex process.</span>





### NeRF(Neural Radiance Fields)




### 3DGS(3D Gaussian Splatting)



## Scene Reconstruction














## Scene Understanding

































